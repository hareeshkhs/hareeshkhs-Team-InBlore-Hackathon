question,answer
write code to rename a file in a folder with timestamp in python,"def rename_with_timestamp(file_name,folder_path):
    try:           
        timestamp = datetime.datetime.now()
        t = [timestamp.year,timestamp.month,timestamp.day,timestamp.hour,timestamp.minute,timestamp.second]
        for i in range(len(t)):
            t[i]=str(t[i])    
        dt = '-'.join(t)
        old_path = folder_path+file_name
        new_path = folder_path+file_name.split('.')[0]+'_'+dt+'.'+file_name.split('.')[1]
        os.rename(old_path,new_path)   
    except Exception as rename_with_timestamp_error:
        print(""Error in renaming file with timestamp: "" + str(rename_with_timestamp_error))"
write code to rename a file in a folder with sequence in python,"def rename_with_sequence(file_name,folder_path,number):
    try:                 
        old_path = folder_path+file_name
        new_path = folder_path+str(number)+'.'+file_name.split('.')[1]
        os.rename(old_path,new_path)   
    except Exception as rename_with_sequence_error:
        print(""Error in renaming file with sequence: "" + str(rename_with_sequence_error))"
write code to rename a file in a folder with extention  in python,"def rename_with_extension(file_name,folder_path,extension):
    try:           
        old_path = folder_path+file_name
        new_path = folder_path+file_name.split('.')[0]+'.'+extension
        os.rename(old_path,new_path)   
    except Exception as rename_with_extension_error:
        print(""Error in renaming file with extension: "" + str(rename_with_extension_error))"
write codeto alter filename of a file in a folder in python ,"def alter_filename(file_name_rule,directory_path):
    try:
        files = os.listdir(directory_path)
        i=0
        for f in files:
            if(file_name_rule.strip().lower()==""timestamp""):
                rename_with_timestamp(f,directory_path)
            if(file_name_rule.strip().lower()==""extension""):
                rename_with_extension(f,directory_path,extension)
            if(file_name_rule.strip().lower()==""sequence""):
                i=i+1
                rename_with_sequence(f,directory_path,i)
    except Exception as alter_filename_error:
        print(""Error in altering filenames: "" + str(alter_filename_error))"
write code to alter filename of a file in a folder in python,"def last_insertion_detail(location):
    if location.upper() == ""S3"":
        print(""Details required from : S3"")
        with open(""test_input\inputs.json"", ""r"") as file:
            s3_inputs = json.load(file)
        s3_connection(
            s3_inputs[""user_region""],
            s3_inputs[""user_access_key""],
            s3_inputs[""user_secret_key""],
            s3_inputs[""bucket_name""],
        )
    elif location.upper() == ""SNOWFLAKE"":
        print(""Details required from : Snowflake"")
        with open(""test_input\inputs.json"", ""r"") as file:
            snowflake_inputs = json.load(file)
        snowflake_connection(
            snowflake_inputs[""username""],
            snowflake_inputs[""password""],
            snowflake_inputs[""account_name""],
            snowflake_inputs[""warehouse_name""],
            snowflake_inputs[""database_name""],
            snowflake_inputs[""user_schema""],
            snowflake_inputs[""user_role""],
            snowflake_inputs[""table""],
            snowflake_inputs[""date_column""],
        )
    else:
        print(
            ""Entered location is: ""
            + location
            + "" . Code is not configured to connect entered location.""
        )"
write code to convert all the sheets inside the given XLSX file into multiple CSV files  in python,"def xlsx_to_csv_converter(input_file_nm: str,outupt_path: str):
    try:
        xls = pd.ExcelFile(input_file_nm)
        for i in range(len(xls.sheet_names)):
            df = pd.read_excel(xls, xls.sheet_names[i])
            df.to_csv (outupt_path+xls.sheet_names[i]+ "".csv"", index = None, header=True)
    except Exception as xlsx_to_csv_converter_error:
        print(""Error in converting xlsx to csv"" + str(xlsx_to_csv_converter_error))
    return True"
write code to add header to csv file if it does not have one in python,"def add_headers (input_file,input_header,output_file): 
    
    with open(input_file, 'r') as csvfile: # open file in read mode 
        csv_test_bytes = csvfile.read(1024)    # Grab a sample of the CSV for format detection.
        csvfile.seek(0)  # Rewind
        has_header = csv.Sniffer().has_header(csv_test_bytes)  # Check to see if there's a header in the file.
        dialect = csv.Sniffer().sniff(csv_test_bytes)  # Check what kind of csv/tsv file we have.
        inputreader = csv.reader(csvfile)
        if has_header == False: 
            input_df = pd.read_csv(input_file, header=None)  # read the csv file in df
            input_df.to_csv(output_file, header=input_header, index=False) # write the data of original csv file to another output file along with header
            print (""Header is successfully added"")
        else:
            print (""File already has header"") # print the message if file already has a header"
write code to remove Erroneous New Lines in a CSV File in python,"def transform_csv(input_file,output_file):

    df = pd.read_csv('input_file')
    #checking the number of empty rows in th csv file
    print (df.isnull().sum())
    #Droping the empty rows
    modifiedDF = df.dropna()
    # Removing extra lines between columns
    modifiedDF.replace('\n', '', regex=True,inplace=True)
    #modifiedDF.replace(to_replace=[r""\\n|\\r"", ""\n|\r""], value=["""",""""], regex=True,inplace=True)
    #Saving it to the csv file 
    modifiedDF.to_csv('output_file',index=False)

    print(""File is transformed"")"
write code to compare if all the csv files have common headers in python,"def compare_headers (input_file_list,sample_header): 
    matching_files = []
    non_matching_files = []
    files_without_header = []
    last_header = []
    last_csv_file = []
    
    for input_csv_file in input_file_list:
        with open(input_csv_file, 'r') as csvfile: #`with open(input_csv_file, 'r') as csvfile:` for Python 3
            csv_test_bytes = csvfile.read(1024)  # Grab a sample of the CSV for format detection.
            csvfile.seek(0)  # Rewind
            has_header = csv.Sniffer().has_header(csv_test_bytes)  # Check to see if there's a header in the file.
            dialect = csv.Sniffer().sniff(csv_test_bytes)  # Check what kind of csv/tsv file we have.
            inputreader = csv.reader(csvfile)
            header = []
            if has_header:                                    #Proceed if file has header
                header = next(inputreader)
                if sample_header == []:                       #Proceed if user has not entered any header for matching
                    if last_header == []:                     #To cater the first file in the list
                        last_header = header 
                        last_csv_file = input_csv_file
                    else:
                        if header == last_header:
                            if last_csv_file != [] and last_csv_file not in matching_files:
                                matching_files.append(last_csv_file)
                            matching_files.append(input_csv_file)
                            last_header = header 
                            last_csv_file = input_csv_file
                        else:
                            non_matching_files.append(input_csv_file) #Add file to list of non matching files if header of file does not matches with that entered by the user
                else:
                    if last_header == []:                     #To cater the first file in the list
                        if header == sample_header:           #Add file to list of matching files if header of file matches with that entered by the user
                            matching_files.append(input_csv_file)
                            last_header = header
                            last_csv_file = input_csv_file
                        else:
                            non_matching_files.append(input_csv_file) #Add file to list of non matching files if header of file does not matches with that entered by the user
                    else:
                        if header == last_header:
                            if last_csv_file != [] and last_csv_file not in matching_files:
                                matching_files.append(last_csv_file)
                            matching_files.append(input_csv_file)
                            last_header = header
                            last_csv_file = input_csv_file
                        else:
                            non_matching_files.append(input_csv_file) #Add file to list of non matching files if header of file does not matches with that entered by the user
                
            else:
                files_without_header.append(input_csv_file)
    
    if len(files_without_header) == len(input_file_list):
        print(""No file have headers"")
    elif len(matching_files) == len(input_file_list):
        print(""All files have common headers"")
    elif len(non_matching_files) == len(input_file_list):
        print(""No file have common headers"")
    else:
        print (""Following csv files have common headers"")
        print (matching_files)
    if files_without_header != []:
        print (""Following files does not have headers"")
        print (files_without_header)"
write code to fetch data from the Postgres database and convert it to a csv file in python,"def pg_to_sftp():
    for name,creds in sftp_creds.items():
        try:
            # Add your query here. The value inside parenthesis is passed dynamically.
            query=f""""""select * from l1.billing_query_tp where practice_name='{name}' 
            and activity_date::date between current_date - interval '7 days' and current_date """"""
            df=execute_query(query)
            print(df)
            str_date=date.today().strftime(""%Y%m%d"")
            fn=""data_backup""+""_""+str_date+"".csv""
            df.to_csv(f""tmp/{fn}"",index=False)

            # SFTP
            host=creds[0]
            port=int(creds[1])
            username=creds[2]
            password=creds[3]

            source=f""tmp/{fn}""
            target=target_sftp+f""/{fn}""
            
            transport = paramiko.Transport((host, port))
            transport.connect(username = username, password = password)
            sftp = paramiko.SFTPClient.from_transport(transport)
            sftp.put(source,target)
            sftp.close()
            transport.close()
            print(f""Successfully Transferred to {name} sftp"")
        except Exception as e:
            print(f""Error : {e}"")"
write codeto delete the document data from the index in Elasticsearch based on the match condition in python ,"def delete_documents(self, index_name, field_to_match, value_to_match):

        # Query to match the documents to be deleted
        try:
            query = {
                ""query"": {
                    ""match"": {
                        field_to_match: value_to_match
                    }
                }
            }

            print(f""Deleting documents with value {value_to_match} from {index_name}."")

            # Delete documents that match the query
            res = self.__conn.delete_by_query(index=index_name, body=query)

            # Print the number of deleted documents
            print(f""Deleted {res['deleted']} documents from {index_name}."")

        except Exception as e:
            print(
                f""Error in deleting data from index: {str(traceback.format_exc())}""
            )"
write code to replaces values in CSV either on S3 or locally on column or file levels in python,"def replace_values_in_csv(
    column_level_change, input_file_path, output_file_path, change_dict
):
    counter = 0
    if (
        column_level_change == ""NO""
    ):  # exectued in case of change irrescpective of columns
        input_df = pd.read_csv(input_file_path)  # read input data
        change_values = change_dict[""1""]
        input_values = change_values[0]  # read existing values
        output_values = change_values[1]  # read new values
        # check whether new values are present for each input value
        if len(input_values) != len(output_values):
            print(""New values are not provided for all existing values."")
        else:
            # each input value will be replace with respective provided value
            for j in range(len(input_values)):
                replaced_df = input_df.replace(input_values[j], output_values[j])
                input_df = replaced_df
        replaced_df.to_csv(output_file_path)  # save replace dataframe at output path
        print(""Values replaced and file saved on output path successfully."")
    else:  # exectued in case of change based on colums
        input_df = pd.read_csv(input_file_path)  # read input data
        input_columns = list(
            input_df.columns.values
        )  # list of columns present in dataframe
        change_columns_list = list(
            change_dict.keys()
        )  # list of all columns provided for chnage in input
        # Check whether input columns present in dataframe or not
        for i in range(len(change_columns_list)):
            if change_columns_list[i] not in input_columns:
                print(
                    ""Below entered column does not exist in input file: ""
                    + change_columns_list[i]
                )  # error if input column not present in dataframe
                counter = counter + 1
            else:
                change_values = change_dict[change_columns_list[i]]
                input_values = change_values[0]  # read existing values
                output_values = change_values[1]  # read new values
                # check whether new values are present for each input value
                if len(input_values) != len(output_values):
                    print(
                        ""New values are not provided for all existing values for ""
                        + change_columns_list[i]
                        + "" column.""
                    )
                    counter = counter + 1
                else:
                    for j in range(len(input_values)):
                        input_df[change_columns_list[i]] = input_df[
                            change_columns_list[i]
                        ].replace(input_values[j], output_values[j])
        input_df.to_csv(output_file_path)  # save replace dataframe at output path
        # check if one or more column contains error
        if counter >= 1:
            print(
                ""Values replaced for all success columns and file saved on output path successfully.""
            )
        else:
            print(""Values replaced and file saved on output path successfully."")"
write code to removes all the non utf-8 characters from the CSV file provided in python,"def convert_csv_in_utf8(input_path,output_path):
    try:
        files = os.listdir(input_path)
        for file_name in files:
            with open(input_path+file_name, 'r', encoding='ANSI', errors='ignore') as infile:
                with open(output_path+file_name.split('.')[0]+'_utf8.csv', 'w', encoding='utf-8') as outfile:
                 outfile.write(infile.read())
    except Exception as convert_csv_in_utf8:
        print(""Error in converting csv to utf8: "" + str(convert_csv_in_utf8))"